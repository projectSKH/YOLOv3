{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Calculate_mAP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKG-maJ88hjU"
      },
      "source": [
        "# Calculate mean_average_precision(mAP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3P_ypigU7LL"
      },
      "source": [
        "## Read Weight Yolo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeEExV6SU7LM"
      },
      "source": [
        "import os\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np  \n",
        "import pandas as pd\n",
        "import struct\n",
        "import cv2\n",
        "from numpy import expand_dims\n",
        "import tensorflow as tf\n",
        "from skimage.transform import resize\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.models import load_model, Model\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrRBT3OCVU5V",
        "outputId": "ef91510d-7af4-4d0c-e691-83e37f4fa1f5"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            "Sat Jan 30 10:46:47 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHBWgZZ4hFWp"
      },
      "source": [
        "def _conv_block(inp, convs, skip=True):\n",
        "    x = inp\n",
        "    count = 0\n",
        "    \n",
        "    for conv in convs:\n",
        "        if count == (len(convs) - 2) and skip:\n",
        "            skip_connection = x\n",
        "        count += 1\n",
        "        \n",
        "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
        "        x = Conv2D(conv['filter'], \n",
        "                   conv['kernel'], \n",
        "                   strides=conv['stride'], \n",
        "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
        "                   name='conv_' + str(conv['layer_idx']), \n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\n",
        "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\n",
        "    return add([skip_connection, x]) if skip else x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL0M63pkhGVk"
      },
      "source": [
        "def make_yolov3_model():\n",
        "    input_image = Input(shape=(None, None, 3))\n",
        "\n",
        "    # Layer  0 => 4\n",
        "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\n",
        "    # Layer  5 => 8\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\n",
        "    # Layer  9 => 11\n",
        "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\n",
        "    # Layer 12 => 15\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\n",
        "    # Layer 16 => 36\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "        \n",
        "    skip_36 = x\n",
        "        \n",
        "    # Layer 37 => 40\n",
        "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\n",
        "    # Layer 41 => 61\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "        \n",
        "    skip_61 = x\n",
        "        \n",
        "    # Layer 62 => 65\n",
        "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\n",
        "    # Layer 66 => 74\n",
        "    for i in range(3):\n",
        "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "        \n",
        "    # Layer 75 => 79\n",
        "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "\n",
        "    # Layer 80 => 82\n",
        "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "                              {'filter':  18, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "\n",
        "    # Layer 83 => 86\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_61])\n",
        "\n",
        "    # Layer 87 => 91\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "\n",
        "    # Layer 92 => 94\n",
        "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "                              {'filter': 18, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "\n",
        "    # Layer 95 => 98\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_36])\n",
        "\n",
        "    # Layer 99 => 106\n",
        "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "                               {'filter': 18, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "\n",
        "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVy3PdjChTEk"
      },
      "source": [
        "from keras.layers import ( Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate, MaxPooling2D,)\n",
        "\n",
        "from functools import reduce\n",
        "from keras.regularizers import l2\n",
        "\n",
        "model = make_yolov3_model()\n",
        "model.load_weights('/content/drive/MyDrive/NewYolov3onlyTrain/1train14.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlP3LluqU7Lf"
      },
      "source": [
        "input_w, input_h = 416, 416\n",
        "net_h, net_w = 416, 416\n",
        "obj_thresh, nms_thresh = 0.2, 0.3\n",
        "address_test=\"/content/drive/My Drive/widerface/WIDER_val/images\"\n",
        "labels = [\"face\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U79TVajQU7Lo"
      },
      "source": [
        "from numpy import expand_dims\n",
        "def load_image_pixels(filename, shape):\n",
        "    # load the image to get its shape\n",
        "    image = load_img(filename)\n",
        "    width, height = image.size\n",
        "    # load the image with the required size\n",
        "    image = load_img(filename, target_size=shape)\n",
        "    # convert to numpy array\n",
        "    image = img_to_array(image)\n",
        "    # scale pixel values to [0, 1]\n",
        "    image = image.astype('float32')\n",
        "    image /= 255.0\n",
        "    # add a dimension so that we have one sample\n",
        "    image = expand_dims(image, 0)\n",
        "    return image, width, height"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYmGZKu7U7Ls"
      },
      "source": [
        "\n",
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        \n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "        \n",
        "        return self.label\n",
        "    \n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "            \n",
        "        return self.score\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3 \n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "    \n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "    \n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    \n",
        "    return float(intersect) / union\n",
        "\n",
        "def do_nms(boxes, nms_thresh):\n",
        "    if len(boxes) > 0:\n",
        "        nb_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "        \n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h34SS9OrU7Lx"
      },
      "source": [
        "#decode_netout() that will take each one of the NumPy arrays, one at a time, \n",
        "#and decode the candidate bounding boxes and class predictions\n",
        "def decode_netout(netout, anchors, obj_thresh,  net_h, net_w):\n",
        "    grid_h, grid_w = netout.shape[:2]\n",
        "    nb_box = 3\n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "    nb_class = netout.shape[-1] - 5\n",
        "\n",
        "    boxes = []\n",
        "\n",
        "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "\n",
        "    for i in range(grid_h*grid_w):\n",
        "        row = i / grid_w\n",
        "        col = i % grid_w\n",
        "        \n",
        "        for b in range(nb_box):\n",
        "            # 4th element is objectness score\n",
        "            objectness = netout[int(row)][int(col)][b][4]\n",
        "            #objectness = netout[..., :4]\n",
        "            \n",
        "            if(objectness.all() <= obj_thresh): continue\n",
        "            \n",
        "            # first 4 elements are x, y, w, and h\n",
        "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "            \n",
        "\n",
        "            x = (col + x) / grid_w # center position, unit: image width\n",
        "            y = (row + y) / grid_h # center position, unit: image height\n",
        "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "            \n",
        "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height \n",
        "            if w>1: \n",
        "              print('w=',w)\n",
        "            if h>1:\n",
        "              print('h=',h)\n",
        "            # last elements are class probabilities\n",
        "            classes = netout[int(row)][col][b][5:]\n",
        "            \n",
        "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "            #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
        "\n",
        "            boxes.append(box)\n",
        "\n",
        "    return boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnfOU0GbU7Lz"
      },
      "source": [
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "    new_w, new_h = net_w, net_h\n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "        boxes[i].xmin = int((boxes[i].xmin ) * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax )  * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin )  * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax )  * image_h)\n",
        " \n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4S0gsTKU7L2"
      },
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "    list_bb=[]\n",
        "    list_pr=[]\n",
        "    # load the image\n",
        "    data = plt.imread(filename)\n",
        "  # data=cv2.resize(data,(416,416))\n",
        "    # plot the image\n",
        "    plt.imshow(data)\n",
        "    # get the context for drawing boxes\n",
        "    ax = plt.gca()\n",
        "    # plot each box\n",
        "    for i in range(len(v_boxes)):\n",
        "        box = v_boxes[i]\n",
        "        list_1bb=[]\n",
        "        # get coordinates\n",
        "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "        # calculate width and height of the box\n",
        "        width, height = x2 - x1, y2 - y1\n",
        "        # create the shape\n",
        "        rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "        #print(x1,y1,y2,x2)\n",
        "        list_1bb.append(x1)\n",
        "        list_1bb.append(y1)\n",
        "        list_1bb.append(x2)\n",
        "        list_1bb.append(y2)\n",
        "\n",
        "        list_bb.append(list_1bb)\n",
        "        list_pr.append(float(format(v_scores[i]/100, '.2f')))\n",
        "        # draw the box\n",
        "        ax.add_patch(rect)\n",
        "        # draw text and score in top left corner\n",
        "        label = \"%s (%.3f)\" % ('face', v_scores[i])\n",
        "        #print(label)\n",
        "        #plt.text(x1, y1, label, color='red')\n",
        "        \n",
        "        plt.savefig('books_read.png',bbox_inches='tight',dpi=200)\n",
        "    # show the plot\n",
        "  #  plt.show()\n",
        "    return list_bb,list_pr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUtHXoO5U7L4"
      },
      "source": [
        "\n",
        "\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
        "    # enumerate all boxes\n",
        "    for box in boxes:\n",
        "        # enumerate all possible labels\n",
        "        for i in range(1):\n",
        "            # check if the threshold for this label is high enough\n",
        "            \n",
        "            if box.classes[i] > thresh:\n",
        "                v_boxes.append(box)\n",
        "                #print(i,labels[i])\n",
        "                v_labels.append(labels[i])\n",
        "                v_scores.append(box.classes[i]*100)\n",
        "                # don't break, many labels may trigger for one box\n",
        "    return v_boxes, v_labels, v_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJKQwAuCd8is",
        "outputId": "98d46ff8-e9ad-4ae6-9640-3cb54f6b3b38"
      },
      "source": [
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "data=loadmat('/content/wider_easy_val.mat')\n",
        "data.keys()\n",
        "data_name = pd.DataFrame(data['file_list'])[0]\n",
        "data_bb = pd.DataFrame(data['face_bbx_list'])[0]\n",
        "dataname_file = data['event_list']\n",
        "data_invalid = data['invalid_label_list']\n",
        "\n",
        "dict_test_map={}\n",
        "for i in range(61):\n",
        "  lenght=len(data_name[i])\n",
        "  for j in range(lenght):# every image\n",
        "    list_box=[]\n",
        "    name_image = dataname_file[i][0][0]+\"/\"+data_name[i][j][0][0]\n",
        "\n",
        "    if 40<=int(dataname_file[i][0][0].split('-')[0])<=59 :# number of class for easy-medium-hard\n",
        "         array_invalid=data_invalid[i][0]\n",
        "         for k in range(len(array_invalid[j][0] )):#every box\n",
        "            if array_invalid[j][0][k] == 0:\n",
        "              width=data_bb[i][j][0][k][2]\n",
        "              height=data_bb[i][j][0][k][3]\n",
        "              if width>0 and height>0:\n",
        "                  list_box.append(data_bb[i][j][0][k])\n",
        "              else:\n",
        "                print(name_image)\n",
        "                \n",
        "         if len(list_box) != 0:\n",
        "            dict_test_map[name_image]=list_box\n",
        "          #  print(dataname_file[i][0][0].split('-')[0])\n",
        "\n",
        "len(dict_test_map.keys())\n",
        "import numpy as np\n",
        "list_name_imag=dict_test_map.keys()\n",
        "key_list=[]\n",
        "for key in dict_test_map.keys(): \n",
        "        key_list.append(key) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50--Celebration_Or_Party/50_Celebration_Or_Party_houseparty_50_715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbCs5-Fu6f24",
        "outputId": "9f83c6b3-d12c-457e-ad0b-1d7c7ae2043d"
      },
      "source": [
        "len(key_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "952"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ_cAq2sCDqg"
      },
      "source": [
        "listInfoImage=[]\n",
        "listInfoImageGT=[]\n",
        "input_w, input_h = 416, 416\n",
        "\n",
        "\n",
        "# define the anchors\n",
        "anchors = [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119] ,[10, 13, 16, 30, 33, 23] ]\n",
        "# define the probability threshold for detected objects\n",
        "class_threshold = 0.25\n",
        "\n",
        "for index in range(len(key_list)):\n",
        "        \n",
        "      name=key_list[index]\n",
        "\n",
        "      photo_filename =address_test+\"/\"+name+\".jpg\"\n",
        "\n",
        "      image, image_w, image_h = load_image_pixels(photo_filename, (net_w, net_w))\n",
        "\n",
        "      listInfoImageGT.append(np.array((image_w,image_h,dict_test_map[name])))\n",
        "      \n",
        "\n",
        "      # make prediction\n",
        "      yolos = model.predict(image)\n",
        "    \n",
        "      boxes = list()\n",
        "\n",
        "      for i in range(len(yolos)):\n",
        "              # decode the output of the network\n",
        "          boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh,  net_h, net_w)\n",
        "\n",
        "          # correct the sizes of the bounding boxes\n",
        "      correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
        "\n",
        "      # suppress non-maximal boxes\n",
        "      do_nms(boxes, nms_thresh)\n",
        "\n",
        "      # get the details of the detected objects\n",
        "      v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
        "      # summarize what we found\n",
        "  \n",
        "\n",
        "      list_bb,list_pr=draw_boxes(photo_filename, v_boxes, v_labels, v_scores)\n",
        "      listInfoImage.append((image_w,image_h,list_bb,list_pr))\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tx4V47EncKC"
      },
      "source": [
        "\r\n",
        "def gtconvert(listInfoImage):\r\n",
        "  for i in range(len(listInfoImage)):\r\n",
        "    for j in range(len(listInfoImage[i][2])):\r\n",
        "      listInfoImage[i][2][j][2]=listInfoImage[i][2][j][2]+listInfoImage[i][2][j][0]\r\n",
        "      listInfoImage[i][2][j][3]=listInfoImage[i][2][j][3]+listInfoImage[i][2][j][1]\r\n",
        "      \r\n",
        "  return listInfoImage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgemvZNB_Lwu"
      },
      "source": [
        "listInfoImageGT=gtconvert(listInfoImageGT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n52frm2Z-nBG"
      },
      "source": [
        "  \n",
        "from enum import Enum\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "class MethodAveragePrecision(Enum):\n",
        "    \"\"\"\n",
        "    Class representing if the coordinates are relative to the\n",
        "    image size or are absolute values.\n",
        "        Developed by: Rafael Padilla\n",
        "        Last modification: Apr 28 2018\n",
        "    \"\"\"\n",
        "    EveryPointInterpolation = 1\n",
        "    ElevenPointInterpolation = 2\n",
        "\n",
        "class CoordinatesType(Enum):\n",
        "    \"\"\"\n",
        "    Class representing if the coordinates are relative to the\n",
        "    image size or are absolute values.\n",
        "        Developed by: Rafael Padilla\n",
        "        Last modification: Apr 28 2018\n",
        "    \"\"\"\n",
        "    Relative = 1\n",
        "    Absolute = 2\n",
        "\n",
        "\n",
        "class BBType(Enum):\n",
        "    \"\"\"\n",
        "    Class representing if the bounding box is groundtruth or not.\n",
        "        Developed by: Rafael Padilla\n",
        "        Last modification: May 24 2018\n",
        "    \"\"\"\n",
        "    GroundTruth = 1\n",
        "    Detected = 2\n",
        "\n",
        "\n",
        "class BBFormat(Enum):\n",
        "    \"\"\"\n",
        "    Class representing the format of a bounding box.\n",
        "    It can be (X,Y,width,height) => XYWH\n",
        "    or (X1,Y1,X2,Y2) => XYX2Y2\n",
        "        Developed by: Rafael Padilla\n",
        "        Last modification: May 24 2018\n",
        "    \"\"\"\n",
        "    XYWH = 1\n",
        "    XYX2Y2 = 2\n",
        "\n",
        "\n",
        "# size => (width, height) of the image\n",
        "# box => (X1, X2, Y1, Y2) of the bounding box\n",
        "def convertToRelativeValues(size, box):\n",
        "    dw = 1. / (size[0])\n",
        "    dh = 1. / (size[1])\n",
        "    cx = (box[1] + box[0]) / 2.0\n",
        "    cy = (box[3] + box[2]) / 2.0\n",
        "    w = box[1] - box[0]\n",
        "    h = box[3] - box[2]\n",
        "    x = cx * dw\n",
        "    y = cy * dh\n",
        "    w = w * dw\n",
        "    h = h * dh\n",
        "    # x,y => (bounding_box_center)/width_of_the_image\n",
        "    # w => bounding_box_width / width_of_the_image\n",
        "    # h => bounding_box_height / height_of_the_image\n",
        "    return (x, y, w, h)\n",
        "\n",
        "\n",
        "# size => (width, height) of the image\n",
        "# box => (centerX, centerY, w, h) of the bounding box relative to the image\n",
        "def convertToAbsoluteValues(size, box):\n",
        "    # w_box = round(size[0] * box[2])\n",
        "    # h_box = round(size[1] * box[3])\n",
        "    xIn = round(((2 * float(box[0]) - float(box[2])) * size[0] / 2))\n",
        "    yIn = round(((2 * float(box[1]) - float(box[3])) * size[1] / 2))\n",
        "    xEnd = xIn + round(float(box[2]) * size[0])\n",
        "    yEnd = yIn + round(float(box[3]) * size[1])\n",
        "    if xIn < 0:\n",
        "        xIn = 0\n",
        "    if yIn < 0:\n",
        "        yIn = 0\n",
        "    if xEnd >= size[0]:\n",
        "        xEnd = size[0] - 1\n",
        "    if yEnd >= size[1]:\n",
        "        yEnd = size[1] - 1\n",
        "    return (xIn, yIn, xEnd, yEnd)\n",
        "\n",
        "\n",
        "def add_bb_into_image(image, bb, color=(255, 0, 0), thickness=2, label=None):\n",
        "    r = int(color[0])\n",
        "    g = int(color[1])\n",
        "    b = int(color[2])\n",
        "\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    fontScale = 0.5\n",
        "    fontThickness = 1\n",
        "\n",
        "    x1, y1, x2, y2 = bb.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n",
        "    x1 = int(x1)\n",
        "    y1 = int(y1)\n",
        "    x2 = int(x2)\n",
        "    y2 = int(y2)\n",
        "    cv2.rectangle(image, (x1, y1), (x2, y2), (b, g, r), thickness)\n",
        "    # Add label\n",
        "    if label is not None:\n",
        "        # Get size of the text box\n",
        "        (tw, th) = cv2.getTextSize(label, font, fontScale, fontThickness)[0]\n",
        "        # Top-left coord of the textbox\n",
        "        (xin_bb, yin_bb) = (x1 + thickness, y1 - th + int(12.5 * fontScale))\n",
        "        # Checking position of the text top-left (outside or inside the bb)\n",
        "        if yin_bb - th <= 0:  # if outside the image\n",
        "            yin_bb = y1 + th  # put it inside the bb\n",
        "        r_Xin = x1 - int(thickness / 2)\n",
        "        r_Yin = y1 - th - int(thickness / 2)\n",
        "        # Draw filled rectangle to put the text in it\n",
        "        cv2.rectangle(image, (r_Xin, r_Yin - thickness),\n",
        "                      (r_Xin + tw + thickness * 3, r_Yin + th + int(12.5 * fontScale)), (b, g, r),\n",
        "                      -1)\n",
        "        cv2.putText(image, label, (xin_bb, yin_bb), font, fontScale, (0, 0, 0), fontThickness,\n",
        "                    cv2.LINE_AA)\n",
        "    return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6Yw8rtF-YtQ"
      },
      "source": [
        "\n",
        "class BoundingBoxes:\n",
        "    def __init__(self):\n",
        "        self._boundingBoxes = []\n",
        "\n",
        "    def addBoundingBox(self, bb):\n",
        "        self._boundingBoxes.append(bb)\n",
        "\n",
        "    def removeBoundingBox(self, _boundingBox):\n",
        "        for d in self._boundingBoxes:\n",
        "            if BoundingBox.compare(d, _boundingBox):\n",
        "                del self._boundingBoxes[d]\n",
        "                return\n",
        "\n",
        "    def removeAllBoundingBoxes(self):\n",
        "        self._boundingBoxes = []\n",
        "\n",
        "    def getBoundingBoxes(self):\n",
        "        return self._boundingBoxes\n",
        "\n",
        "    def getBoundingBoxByClass(self, classId):\n",
        "        boundingBoxes = []\n",
        "        for d in self._boundingBoxes:\n",
        "            if d.getClassId() == classId:  # get only specified bounding box type\n",
        "                boundingBoxes.append(d)\n",
        "        return boundingBoxes\n",
        "\n",
        "    def getClasses(self):\n",
        "        classes = []\n",
        "        for d in self._boundingBoxes:\n",
        "            c = d.getClassId()\n",
        "            if c not in classes:\n",
        "                classes.append(c)\n",
        "        return classes\n",
        "\n",
        "    def getBoundingBoxesByType(self, bbType):\n",
        "        # get only specified bb type\n",
        "        return [d for d in self._boundingBoxes if d.getBBType() == bbType]\n",
        "\n",
        "    def getBoundingBoxesByImageName(self, imageName):\n",
        "        # get only specified bb type\n",
        "        return [d for d in self._boundingBoxes if d.getImageName() == imageName]\n",
        "\n",
        "    def count(self, bbType=None):\n",
        "        if bbType is None:  # Return all bounding boxes\n",
        "            return len(self._boundingBoxes)\n",
        "        count = 0\n",
        "        for d in self._boundingBoxes:\n",
        "            if d.getBBType() == bbType:  # get only specified bb type\n",
        "                count += 1\n",
        "        return count\n",
        "\n",
        "    def clone(self):\n",
        "        newBoundingBoxes = BoundingBoxes()\n",
        "        for d in self._boundingBoxes:\n",
        "            det = BoundingBox.clone(d)\n",
        "            newBoundingBoxes.addBoundingBox(det)\n",
        "        return newBoundingBoxes\n",
        "\n",
        "    def drawAllBoundingBoxes(self, image, imageName):\n",
        "        bbxes = self.getBoundingBoxesByImageName(imageName)\n",
        "        for bb in bbxes:\n",
        "            if bb.getBBType() == BBType.GroundTruth:  # if ground truth\n",
        "                image = add_bb_into_image(image, bb, color=(0, 255, 0))  # green\n",
        "            else:  # if detection\n",
        "                image = add_bb_into_image(image, bb, color=(255, 0, 0))  # red\n",
        "        return image\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKRBBQPD-e4e"
      },
      "source": [
        "\n",
        "class BoundingBox:\n",
        "    def __init__(self,imageName,classId,x,y,w,h,typeCoordinates=CoordinatesType.Absolute,imgSize=None,bbType=BBType.GroundTruth,classConfidence=None,format=BBFormat.XYWH):\n",
        "        \"\"\"Constructor.\n",
        "        Args:\n",
        "            imageName: String representing the image name.\n",
        "            classId: String value representing class id.\n",
        "            x: Float value representing the X upper-left coordinate of the bounding box.\n",
        "            y: Float value representing the Y upper-left coordinate of the bounding box.\n",
        "            w: Float value representing the width bounding box.\n",
        "            h: Float value representing the height bounding box.\n",
        "            typeCoordinates: (optional) Enum (Relative or Absolute) represents if the bounding box\n",
        "            coordinates (x,y,w,h) are absolute or relative to size of the image. Default:'Absolute'.\n",
        "            imgSize: (optional) 2D vector (width, height)=>(int, int) represents the size of the\n",
        "            image of the bounding box. If typeCoordinates is 'Relative', imgSize is required.\n",
        "            bbType: (optional) Enum (Groundtruth or Detection) identifies if the bounding box\n",
        "            represents a ground truth or a detection. If it is a detection, the classConfidence has\n",
        "            to be informed.\n",
        "            classConfidence: (optional) Float value representing the confidence of the detected\n",
        "            class. If detectionType is Detection, classConfidence needs to be informed.\n",
        "            format: (optional) Enum (BBFormat.XYWH or BBFormat.XYX2Y2) indicating the format of the\n",
        "            coordinates of the bounding boxes. BBFormat.XYWH: <left> <top> <width> <height>\n",
        "            BBFormat.XYX2Y2: <left> <top> <right> <bottom>.\n",
        "        \"\"\"\n",
        "        self._imageName = imageName\n",
        "        self._typeCoordinates = typeCoordinates\n",
        "        if typeCoordinates == CoordinatesType.Relative and imgSize is None:\n",
        "            raise IOError(\n",
        "                'Parameter \\'imgSize\\' is required. It is necessary to inform the image size.')\n",
        "        if bbType == BBType.Detected and classConfidence is None:\n",
        "            raise IOError(\n",
        "                'For bbType=\\'Detection\\', it is necessary to inform the classConfidence value.')\n",
        "        # if classConfidence != None and (classConfidence < 0 or classConfidence > 1):\n",
        "        # raise IOError('classConfidence value must be a real value between 0 and 1. Value: %f' %\n",
        "        # classConfidence)\n",
        "\n",
        "        self._classConfidence = classConfidence\n",
        "        self._bbType = bbType\n",
        "        self._classId = classId\n",
        "        self._format = format\n",
        "\n",
        "        # If relative coordinates, convert to absolute values\n",
        "        # For relative coords: (x,y,w,h)=(X_center/img_width , Y_center/img_height)\n",
        "        if (typeCoordinates == CoordinatesType.Relative):\n",
        "            (self._x, self._y, self._w, self._h) = convertToAbsoluteValues(imgSize, (x, y, w, h))\n",
        "            self._width_img = imgSize[0]\n",
        "            self._height_img = imgSize[1]\n",
        "            if format == BBFormat.XYWH:\n",
        "                self._x2 = self._w\n",
        "                self._y2 = self._h\n",
        "                self._w = self._x2 - self._x\n",
        "                self._h = self._y2 - self._y\n",
        "            else:\n",
        "                raise IOError(\n",
        "                    'For relative coordinates, the format must be XYWH (x,y,width,height)')\n",
        "        # For absolute coords: (x,y,w,h)=real bb coords\n",
        "        else:\n",
        "            self._x = x\n",
        "            self._y = y\n",
        "            if format == BBFormat.XYWH:\n",
        "                self._w = w\n",
        "                self._h = h\n",
        "                self._x2 = self._x + self._w\n",
        "                self._y2 = self._y + self._h\n",
        "            else:  # format == BBFormat.XYX2Y2: <left> <top> <right> <bottom>.\n",
        "                self._x2 = w\n",
        "                self._y2 = h\n",
        "                self._w = self._x2 - self._x\n",
        "                self._h = self._y2 - self._y\n",
        "        if imgSize is None:\n",
        "            self._width_img = None\n",
        "            self._height_img = None\n",
        "        else:\n",
        "            self._width_img = imgSize[0]\n",
        "            self._height_img = imgSize[1]\n",
        "\n",
        "    def getAbsoluteBoundingBox(self, format=BBFormat.XYWH):\n",
        "        if format == BBFormat.XYWH:\n",
        "            return (self._x, self._y, self._w, self._h)\n",
        "        elif format == BBFormat.XYX2Y2:\n",
        "            return (self._x, self._y, self._x2, self._y2)\n",
        "\n",
        "    def getRelativeBoundingBox(self, imgSize=None):\n",
        "        if imgSize is None and self._width_img is None and self._height_img is None:\n",
        "            raise IOError(\n",
        "                'Parameter \\'imgSize\\' is required. It is necessary to inform the image size.')\n",
        "        if imgSize is None:\n",
        "            return convertToRelativeValues((imgSize[0], imgSize[1]),\n",
        "                                           (self._x, self._y, self._w, self._h))\n",
        "        else:\n",
        "            return convertToRelativeValues((self._width_img, self._height_img),\n",
        "                                           (self._x, self._y, self._w, self._h))\n",
        "\n",
        "    def getImageName(self):\n",
        "        return self._imageName\n",
        "\n",
        "    def getConfidence(self):\n",
        "        return self._classConfidence\n",
        "\n",
        "    def getFormat(self):\n",
        "        return self._format\n",
        "\n",
        "    def getClassId(self):\n",
        "        return self._classId\n",
        "\n",
        "    def getImageSize(self):\n",
        "        return (self._width_img, self._height_img)\n",
        "\n",
        "    def getCoordinatesType(self):\n",
        "        return self._typeCoordinates\n",
        "\n",
        "    def getBBType(self):\n",
        "        return self._bbType\n",
        "\n",
        "    @staticmethod\n",
        "    def compare(det1, det2):\n",
        "        det1BB = det1.getAbsoluteBoundingBox()\n",
        "        det1ImgSize = det1.getImageSize()\n",
        "        det2BB = det2.getAbsoluteBoundingBox()\n",
        "        det2ImgSize = det2.getImageSize()\n",
        "\n",
        "        if det1.getClassId() == det2.getClassId() and \\\n",
        "           det1.classConfidence == det2.classConfidenc() and \\\n",
        "           det1BB[0] == det2BB[0] and \\\n",
        "           det1BB[1] == det2BB[1] and \\\n",
        "           det1BB[2] == det2BB[2] and \\\n",
        "           det1BB[3] == det2BB[3] and \\\n",
        "           det1ImgSize[0] == det1ImgSize[0] and \\\n",
        "           det2ImgSize[1] == det2ImgSize[1]:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    @staticmethod\n",
        "    def clone(boundingBox):\n",
        "        absBB = boundingBox.getAbsoluteBoundingBox(format=BBFormat.XYWH)\n",
        "        # return (self._x,self._y,self._x2,self._y2)\n",
        "        newBoundingBox = BoundingBox(\n",
        "            boundingBox.getImageName(),\n",
        "            boundingBox.getClassId(),\n",
        "            absBB[0],\n",
        "            absBB[1],\n",
        "            absBB[2],\n",
        "            absBB[3],\n",
        "            typeCoordinates=boundingBox.getCoordinatesType(),\n",
        "            imgSize=boundingBox.getImageSize(),\n",
        "            bbType=boundingBox.getBBType(),\n",
        "            classConfidence=boundingBox.getConfidence(),\n",
        "            format=BBFormat.XYWH)\n",
        "        return newBoundingBox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frj4yfu--h_a"
      },
      "source": [
        "bb=BoundingBoxes();\n",
        "\n",
        "for i in range(len(key_list)):\n",
        "  for j in range(len(listInfoImageGT[i][2])):\n",
        "    bb.addBoundingBox(BoundingBox(str(listInfoImageGT[i][0]),1,listInfoImageGT[i][2][j][0], listInfoImageGT[i][2][j][1], listInfoImageGT[i][2][j][2], listInfoImageGT[i][2][j][3],bbType=BBType.GroundTruth))\n",
        "\n",
        "  for p in range(len(listInfoImage[i][2])):\n",
        "    bb.addBoundingBox(BoundingBox(str(listInfoImage[i][0]),1,listInfoImage[i][2][p][0], listInfoImage[i][2][p][1], listInfoImage[i][2][p][2], listInfoImage[i][2][p][3],bbType=BBType.Detected,classConfidence=listInfoImage[i][3][p]))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zz0bdwV_0WB"
      },
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Evaluator:\n",
        "    def GetPascalVOCMetrics(self,\n",
        "                            boundingboxes,\n",
        "                            IOUThreshold=0.5,\n",
        "                            method=MethodAveragePrecision.EveryPointInterpolation):\n",
        "        \"\"\"Get the metrics used by the VOC Pascal 2012 challenge.\n",
        "        Get\n",
        "        Args:\n",
        "            boundingboxes: Object of the class BoundingBoxes representing ground truth and detected\n",
        "            bounding boxes;\n",
        "            IOUThreshold: IOU threshold indicating which detections will be considered TP or FP\n",
        "            (default value = 0.5);\n",
        "            method (default = EveryPointInterpolation): It can be calculated as the implementation\n",
        "            in the official PASCAL VOC toolkit (EveryPointInterpolation), or applying the 11-point\n",
        "            interpolatio as described in the paper \"The PASCAL Visual Object Classes(VOC) Challenge\"\n",
        "            or EveryPointInterpolation\"  (ElevenPointInterpolation);\n",
        "        Returns:\n",
        "            A list of dictionaries. Each dictionary contains information and metrics of each class.\n",
        "            The keys of each dictionary are:\n",
        "            dict['class']: class representing the current dictionary;\n",
        "            dict['precision']: array with the precision values;\n",
        "            dict['recall']: array with the recall values;\n",
        "            dict['AP']: average precision;\n",
        "            dict['interpolated precision']: interpolated precision values;\n",
        "            dict['interpolated recall']: interpolated recall values;\n",
        "            dict['total positives']: total number of ground truth positives;\n",
        "            dict['total TP']: total number of True Positive detections;\n",
        "            dict['total FP']: total number of False Negative detections;\n",
        "        \"\"\"\n",
        "        ret = []  # list containing metrics (precision, recall, average precision) of each class\n",
        "        # List with all ground truths (Ex: [imageName,class,confidence=1, (bb coordinates XYX2Y2)])\n",
        "        groundTruths = []\n",
        "        # List with all detections (Ex: [imageName,class,confidence,(bb coordinates XYX2Y2)])\n",
        "        detections = []\n",
        "        # Get all classes\n",
        "        classes = []\n",
        "        # Loop through all bounding boxes and separate them into GTs and detections\n",
        "        for bb in boundingboxes.getBoundingBoxes():\n",
        "            # [imageName, class, confidence, (bb coordinates XYX2Y2)]\n",
        "            if bb.getBBType() == BBType.GroundTruth:\n",
        "                groundTruths.append([\n",
        "                    bb.getImageName(),\n",
        "                    bb.getClassId(), 1,\n",
        "                    bb.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n",
        "                ])\n",
        "            else:\n",
        "                detections.append([\n",
        "                    bb.getImageName(),\n",
        "                    bb.getClassId(),\n",
        "                    bb.getConfidence(),\n",
        "                    bb.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n",
        "                ])\n",
        "            # get class\n",
        "            if bb.getClassId() not in classes:\n",
        "                classes.append(bb.getClassId())\n",
        "        classes = sorted(classes)\n",
        "        # Precision x Recall is obtained individually by each class\n",
        "        # Loop through by classes\n",
        "        for c in classes:\n",
        "            # Get only detection of class c\n",
        "            dects = []\n",
        "            [dects.append(d) for d in detections if d[1] == c]\n",
        "            # Get only ground truths of class c\n",
        "            gts = []\n",
        "            [gts.append(g) for g in groundTruths if g[1] == c]\n",
        "            npos = len(gts)\n",
        "            # sort detections by decreasing confidence\n",
        "            dects = sorted(dects, key=lambda conf: conf[2], reverse=True)\n",
        "            TP = np.zeros(len(dects))\n",
        "            FP = np.zeros(len(dects))\n",
        "            # create dictionary with amount of gts for each image\n",
        "            det = Counter([cc[0] for cc in gts])\n",
        "            for key, val in det.items():\n",
        "                det[key] = np.zeros(val)\n",
        "            # print(\"Evaluating class: %s (%d detections)\" % (str(c), len(dects)))\n",
        "            # Loop through detections\n",
        "            for d in range(len(dects)):\n",
        "                # print('dect %s => %s' % (dects[d][0], dects[d][3],))\n",
        "                # Find ground truth image\n",
        "                gt = [gt for gt in gts if gt[0] == dects[d][0]]\n",
        "                iouMax = sys.float_info.min\n",
        "                for j in range(len(gt)):\n",
        "                    # print('Ground truth gt => %s' % (gt[j][3],))\n",
        "                    iou = Evaluator.iou(dects[d][3], gt[j][3])\n",
        "                    if iou > iouMax:\n",
        "                        iouMax = iou\n",
        "                        jmax = j\n",
        "                # Assign detection as true positive/don't care/false positive\n",
        "                if iouMax >= IOUThreshold:\n",
        "                    if det[dects[d][0]][jmax] == 0:\n",
        "                        TP[d] = 1  # count as true positive\n",
        "                        det[dects[d][0]][jmax] = 1  # flag as already 'seen'\n",
        "                        # print(\"TP\")\n",
        "                    else:\n",
        "                        FP[d] = 1  # count as false positive\n",
        "                        # print(\"FP\")\n",
        "                # - A detected \"cat\" is overlaped with a GT \"cat\" with IOU >= IOUThreshold.\n",
        "                else:\n",
        "                    FP[d] = 1  # count as false positive\n",
        "                    # print(\"FP\")\n",
        "            # compute precision, recall and average precision\n",
        "            acc_FP = np.cumsum(FP)\n",
        "            acc_TP = np.cumsum(TP)\n",
        "            rec = acc_TP / npos\n",
        "            prec = np.divide(acc_TP, (acc_FP + acc_TP))\n",
        "            # Depending on the method, call the right implementation\n",
        "            if method == MethodAveragePrecision.EveryPointInterpolation:\n",
        "                [ap, mpre, mrec, ii] = Evaluator.CalculateAveragePrecision(rec, prec)\n",
        "            else:\n",
        "                [ap, mpre, mrec, _] = Evaluator.ElevenPointInterpolatedAP(rec, prec)\n",
        "            # add class result in the dictionary to be returned\n",
        "            r = {\n",
        "                'class': c,\n",
        "                'precision': prec,\n",
        "                'recall': rec,\n",
        "                'AP': ap,\n",
        "                'interpolated precision': mpre,\n",
        "                'interpolated recall': mrec,\n",
        "                'total positives': npos,\n",
        "                'total TP': np.sum(TP),\n",
        "                'total FP': np.sum(FP)\n",
        "            }\n",
        "            ret.append(r)\n",
        "        return ret\n",
        "    @staticmethod\n",
        "    def CalculateAveragePrecision(rec, prec):\n",
        "        mrec = []\n",
        "        mrec.append(0)\n",
        "        [mrec.append(e) for e in rec]\n",
        "        mrec.append(1)\n",
        "        mpre = []\n",
        "        mpre.append(0)\n",
        "        [mpre.append(e) for e in prec]\n",
        "        mpre.append(0)\n",
        "        for i in range(len(mpre) - 1, 0, -1):\n",
        "            mpre[i - 1] = max(mpre[i - 1], mpre[i])\n",
        "        ii = []\n",
        "        for i in range(len(mrec) - 1):\n",
        "            if mrec[1:][i] != mrec[0:-1][i]:\n",
        "                ii.append(i + 1)\n",
        "        ap = 0\n",
        "        for i in ii:\n",
        "            ap = ap + np.sum((mrec[i] - mrec[i - 1]) * mpre[i])\n",
        "        # return [ap, mpre[1:len(mpre)-1], mrec[1:len(mpre)-1], ii]\n",
        "        return [ap, mpre[0:len(mpre) - 1], mrec[0:len(mpre) - 1], ii]\n",
        "    \n",
        "    @staticmethod\n",
        "    def iou(boxA, boxB):\n",
        "        # if boxes dont intersect\n",
        "        if Evaluator._boxesIntersect(boxA, boxB) is False:\n",
        "            return 0\n",
        "        interArea = Evaluator._getIntersectionArea(boxA, boxB)\n",
        "        #print(boxA,boxB,interArea)\n",
        "        union = Evaluator._getUnionAreas(boxA, boxB, interArea=interArea)\n",
        "        # intersection over union\n",
        "        \n",
        "        iou = interArea / union\n",
        "        assert iou >= 0\n",
        "        return iou\n",
        "    @staticmethod\n",
        "    def _boxesIntersect(boxA, boxB):\n",
        "        if boxA[0] > boxB[2]:\n",
        "            return False  # boxA is right of boxB\n",
        "        if boxB[0] > boxA[2]:\n",
        "            return False  # boxA is left of boxB\n",
        "        if boxA[3] < boxB[1]:\n",
        "            return False  # boxA is above boxB\n",
        "        if boxA[1] > boxB[3]:\n",
        "            return False  # boxA is below boxB\n",
        "        return True\n",
        "    @staticmethod\n",
        "    def _getIntersectionArea(boxA, boxB):\n",
        "        xA = max(boxA[0], boxB[0])\n",
        "        yA = max(boxA[1], boxB[1])\n",
        "        xB = min(boxA[2], boxB[2])\n",
        "        yB = min(boxA[3], boxB[3])\n",
        "        # intersection area\n",
        "        return (xB - xA + 1) * (yB - yA + 1)\n",
        "    @staticmethod\n",
        "    def _getUnionAreas(boxA, boxB, interArea=None):\n",
        "        area_A = Evaluator._getArea(boxA)\n",
        "        area_B = Evaluator._getArea(boxB)\n",
        "        if interArea is None:\n",
        "            interArea = Evaluator._getIntersectionArea(boxA, boxB)\n",
        "        return float(area_A + area_B - interArea)\n",
        "    @staticmethod\n",
        "    def _getArea(box):\n",
        "        return (box[2] - box[0] + 1) * (box[3] - box[1] + 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lU8PqOj6pbd"
      },
      "source": [
        "e=Evaluator()\r\n",
        "calculate=e.GetPascalVOCMetrics(boundingboxes=bb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIhE2lAiEE-n"
      },
      "source": [
        "precision=calculate[0]['precision']\n",
        "recall=calculate[0]['recall']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "GRL6-3bfMdfd",
        "outputId": "96eb2ef5-5ef9-46a2-bac6-73cf74d3e470"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(recall,precision)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb3860447b8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
