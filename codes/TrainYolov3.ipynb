{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TrainYolov3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jENL1RT69D0g"
      },
      "source": [
        "# download weight for yolov3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT_Zovmf89gK"
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwN5SXN68_Th"
      },
      "source": [
        "# import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjVktg5hKJXz"
      },
      "source": [
        "import os\r\n",
        "import scipy.io\r\n",
        "import scipy.misc\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import struct\r\n",
        "import cv2\r\n",
        "from numpy import expand_dims\r\n",
        "from skimage.transform import resize\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from keras import backend as K\r\n",
        "from keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\r\n",
        "from keras.layers import Conv2D, MaxPool2D,Dropout, Dense,Lambda, Input, concatenate, GlobalAveragePooling2D, AveragePooling2D,Flatten\r\n",
        "from keras.models import load_model, Model\r\n",
        "from keras.optimizers import Adam\r\n",
        "\r\n",
        "from keras.layers.merge import add, concatenate\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from matplotlib.pyplot import imshow\r\n",
        "from matplotlib.patches import Rectangle\r\n",
        "\r\n",
        "from functools import reduce\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\r\n",
        "from keras import callbacks\r\n",
        "import re\r\n",
        "\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9hvuFpXMNah",
        "outputId": "cee19f40-b811-4a91-e3b6-f7c9ed63b972"
      },
      "source": [
        "from google.colab import drive\r\n",
        " \r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z3AXdziKkfp"
      },
      "source": [
        "def _conv_block(inp, convs, skip=True):\r\n",
        "    x = inp\r\n",
        "    count = 0\r\n",
        "    \r\n",
        "    for conv in convs:\r\n",
        "        if count == (len(convs) - 2) and skip:\r\n",
        "            skip_connection = x\r\n",
        "        count += 1\r\n",
        "        \r\n",
        "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\r\n",
        "        x = Conv2D(conv['filter'], \r\n",
        "                   conv['kernel'], \r\n",
        "                   strides=conv['stride'], \r\n",
        "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\r\n",
        "                   name='conv_' + str(conv['layer_idx']), \r\n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\r\n",
        "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\r\n",
        "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\r\n",
        "\r\n",
        "    return add([skip_connection, x]) if skip else x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK7zqU3QKnsS"
      },
      "source": [
        "def make_yolov3_model():\r\n",
        "    input_image = Input(shape=(None, None, 3))\r\n",
        "\r\n",
        "    # Layer  0 => 4\r\n",
        "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\r\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\r\n",
        "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\r\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\r\n",
        "\r\n",
        "    # Layer  5 => 8\r\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\r\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\r\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\r\n",
        "\r\n",
        "    # Layer  9 => 11\r\n",
        "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\r\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\r\n",
        "\r\n",
        "    # Layer 12 => 15\r\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\r\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\r\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\r\n",
        "\r\n",
        "    # Layer 16 => 36\r\n",
        "    for i in range(7):\r\n",
        "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\r\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\r\n",
        "        \r\n",
        "    skip_36 = x\r\n",
        "        \r\n",
        "    # Layer 37 => 40\r\n",
        "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\r\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\r\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\r\n",
        "\r\n",
        "    # Layer 41 => 61\r\n",
        "    for i in range(7):\r\n",
        "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\r\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\r\n",
        "        \r\n",
        "    skip_61 = x\r\n",
        "        \r\n",
        "    # Layer 62 => 65\r\n",
        "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\r\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\r\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\r\n",
        "\r\n",
        "    # Layer 66 => 74\r\n",
        "    for i in range(3):\r\n",
        "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\r\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\r\n",
        "        \r\n",
        "    # Layer 75 => 79\r\n",
        "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\r\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\r\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\r\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\r\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\r\n",
        "\r\n",
        "    # Layer 80 => 82\r\n",
        "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\r\n",
        "                              {'filter':  18, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\r\n",
        "\r\n",
        "    # Layer 83 => 86\r\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\r\n",
        "    x = UpSampling2D(2)(x)\r\n",
        "    x = concatenate([x, skip_61])\r\n",
        "\r\n",
        "    # Layer 87 => 91\r\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\r\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\r\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\r\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\r\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\r\n",
        "\r\n",
        "    # Layer 92 => 94\r\n",
        "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\r\n",
        "                              {'filter': 18, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\r\n",
        "\r\n",
        "    # Layer 95 => 98\r\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\r\n",
        "    x = UpSampling2D(2)(x)\r\n",
        "    x = concatenate([x, skip_36])\r\n",
        "\r\n",
        "    # Layer 99 => 106\r\n",
        "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\r\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\r\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\r\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\r\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\r\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\r\n",
        "                               {'filter': 18, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\r\n",
        "\r\n",
        "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \r\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u14nHYwVLPdJ"
      },
      "source": [
        "   \"\"\"Return iou tensor\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    b1: tensor, shape=(i1,...,iN, 4), xywh\r\n",
        "    b2: tensor, shape=(j, 4), xywh\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    iou: tensor, shape=(i1,...,iN, j)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "def box_iou(b1, b2):\r\n",
        "\r\n",
        "    # Expand dim to apply broadcasting.\r\n",
        "    b1 = K.expand_dims(b1, -2)\r\n",
        "    b1_xy = b1[..., :2]\r\n",
        "    b1_wh = b1[..., 2:4]\r\n",
        "    b1_wh_half = b1_wh / 2.0\r\n",
        "    b1_mins = b1_xy - b1_wh_half\r\n",
        "    b1_maxes = b1_xy + b1_wh_half\r\n",
        "\r\n",
        "    # Expand dim to apply broadcasting.\r\n",
        "    b2 = K.expand_dims(b2, 0)\r\n",
        "    b2_xy = b2[..., :2]\r\n",
        "    b2_wh = b2[..., 2:4]\r\n",
        "    b2_wh_half = b2_wh / 2.0\r\n",
        "    b2_mins = b2_xy - b2_wh_half\r\n",
        "    b2_maxes = b2_xy + b2_wh_half\r\n",
        "\r\n",
        "    intersect_mins = K.maximum(b1_mins, b2_mins)\r\n",
        "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\r\n",
        "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.0)\r\n",
        "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\r\n",
        "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\r\n",
        "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\r\n",
        "    iou = intersect_area / (b1_area + b2_area - intersect_area)\r\n",
        "\r\n",
        "    return iou"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2vF2sNXYvN0"
      },
      "source": [
        "\r\n",
        "def get_random_data( address , key , data, input_shape, random=True, max_boxes=2000, jitter=0.3, hue=0.1, sat=1.5,\r\n",
        "                    val=1.5, proc_img=True,):\r\n",
        "    \"\"\"random preprocessing for real-time data augmentation\"\"\"\r\n",
        "\r\n",
        "    image = Image.open(address+key)\r\n",
        "    \r\n",
        "    iw, ih = image.size\r\n",
        "    h, w = input_shape\r\n",
        "    \r\n",
        "    box = np.array(data[key])\r\n",
        "\r\n",
        "\r\n",
        "    if not random:\r\n",
        "        # resize image\r\n",
        "        scale = min(w / iw, h / ih)\r\n",
        "        nw = int(iw * scale)\r\n",
        "        nh = int(ih * scale)\r\n",
        "        dx = (w - nw) // 2\r\n",
        "        dy = (h - nh) // 2\r\n",
        "        image_data = 0\r\n",
        "        if proc_img:\r\n",
        "            image = image.resize((nw, nh), Image.BICUBIC)\r\n",
        "            new_image = Image.new(\"RGB\", (w, h), (128, 128, 128))\r\n",
        "            new_image.paste(image, (dx, dy))\r\n",
        "            image_data = np.array(new_image) / 255.0\r\n",
        "\r\n",
        "        # correct boxes\r\n",
        "        box_data = np.zeros((max_boxes, 5))\r\n",
        "        if len(box) > 0:\r\n",
        "            np.random.shuffle(box)\r\n",
        "            if len(box) > max_boxes:\r\n",
        "                box = box[:max_boxes]\r\n",
        "            box[:, [0, 2]] = box[:, [0, 2]] * scale + dx\r\n",
        "            box[:, [1, 3]] = box[:, [1, 3]] * scale + dy\r\n",
        "            box_data[: len(box)] = box\r\n",
        "\r\n",
        "        return image_data, box_data\r\n",
        "\r\n",
        "    # resize image\r\n",
        "    new_ar = w / h * rand(1 - jitter, 1 + jitter) / rand(1 - jitter, 1 + jitter)\r\n",
        "    scale = rand(0.25, 2)\r\n",
        "    if new_ar < 1:\r\n",
        "        nh = int(scale * h)\r\n",
        "        nw = int(nh * new_ar)\r\n",
        "    else:\r\n",
        "        nw = int(scale * w)\r\n",
        "        nh = int(nw / new_ar)\r\n",
        "    image = image.resize((nw, nh), Image.BICUBIC)\r\n",
        "\r\n",
        "    # place image\r\n",
        "    dx = int(rand(0, w - nw))\r\n",
        "    dy = int(rand(0, h - nh))\r\n",
        "    new_image = Image.new(\"RGB\", (w, h), (128, 128, 128))\r\n",
        "    new_image.paste(image, (dx, dy))\r\n",
        "    image = new_image\r\n",
        "\r\n",
        "    # flip image or not\r\n",
        "    flip = rand() < 0.5\r\n",
        "    if flip:\r\n",
        "        image = image.transpose(Image.FLIP_LEFT_RIGHT)\r\n",
        "\r\n",
        "    # distort image\r\n",
        "    hue = rand(-hue, hue)\r\n",
        "    sat = rand(1, sat) if rand() < 0.5 else 1 / rand(1, sat)\r\n",
        "    val = rand(1, val) if rand() < 0.5 else 1 / rand(1, val)\r\n",
        "    x = rgb_to_hsv(np.array(image) / 255.0)\r\n",
        "    x[..., 0] += hue\r\n",
        "    x[..., 0][x[..., 0] > 1] -= 1\r\n",
        "    x[..., 0][x[..., 0] < 0] += 1\r\n",
        "    x[..., 1] *= sat\r\n",
        "    x[..., 2] *= val\r\n",
        "    x[x > 1] = 1\r\n",
        "    x[x < 0] = 0\r\n",
        "    image_data = hsv_to_rgb(x)  # numpy array, 0 to 1\r\n",
        "\r\n",
        "    # make gray\r\n",
        "    gray = rand() < 0.2\r\n",
        "    if gray:\r\n",
        "        image_gray = np.dot(image_data, [0.299, 0.587, 0.114])\r\n",
        "        # a gray RGB image is GGG\r\n",
        "        image_data = np.moveaxis(np.stack([image_gray, image_gray, image_gray]), 0, -1)\r\n",
        "\r\n",
        "    # invert colors\r\n",
        "    invert = rand() < 0.1\r\n",
        "    if invert:\r\n",
        "        image_data = 1.0 - image_data\r\n",
        "\r\n",
        "    # correct boxes\r\n",
        "    box_data = np.zeros((max_boxes, 5))\r\n",
        "    if len(box) > 0:\r\n",
        "        np.random.shuffle(box)\r\n",
        "        \r\n",
        "        box[:, [0, 2]] = box[:, [0, 2]] * nw / iw + dx\r\n",
        "        box[:, [1, 3]] = box[:, [1, 3]] * nh / ih + dy\r\n",
        "        if flip:\r\n",
        "            box[:, [0, 2]] = w - box[:, [2, 0]]\r\n",
        "        box[:, 0:2][box[:, 0:2] < 0] = 0\r\n",
        "        box[:, 2][box[:, 2] > w] = w\r\n",
        "        box[:, 3][box[:, 3] > h] = h\r\n",
        "        box_w = box[:, 2] - box[:, 0]\r\n",
        "        box_h = box[:, 3] - box[:, 1]\r\n",
        "    \r\n",
        "        box = box[np.logical_and(box_w > 1, box_h > 1)]  # discard invalid box\r\n",
        "        \r\n",
        "        if len(box) > max_boxes:\r\n",
        "            box = box[:max_boxes]\r\n",
        "        box_data[: len(box)] = box\r\n",
        "\r\n",
        "    return image_data, box_data\r\n",
        "  \r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsrVaAqZLNG6"
      },
      "source": [
        "   \"\"\"Return yolo_loss tensor\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\r\n",
        "    y_true: list of array, the output of preprocess_true_boxes\r\n",
        "    anchors: array, shape=(N, 2), wh\r\n",
        "    num_classes: integer\r\n",
        "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    loss: tensor, shape=(1,)\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "\r\n",
        "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\r\n",
        "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\r\n",
        "    num_anchors = len(anchors)\r\n",
        "    # Reshape to batch, height, width, num_anchors, box_params.\r\n",
        "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\r\n",
        "\r\n",
        "    grid_shape = K.shape(feats)[1:3]  # height, width\r\n",
        "    grid_y = K.tile(\r\n",
        "        K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\r\n",
        "        [1, grid_shape[1], 1, 1],\r\n",
        "    )# e.g \r\n",
        "    grid_x = K.tile(\r\n",
        "        K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\r\n",
        "        [grid_shape[0], 1, 1, 1],\r\n",
        "    )# <tf.Tensor: shape=(32, 32, 1, 1), dtype=int32\r\n",
        "    grid = K.concatenate([grid_x, grid_y]) #e.g <tf.Tensor: shape=(32, 32, 1, 2), dtype=int32\r\n",
        "    grid = K.cast(grid, K.dtype(feats))\r\n",
        "\r\n",
        "    feats = K.reshape(\r\n",
        "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5]\r\n",
        "    )\r\n",
        "\r\n",
        "    # Adjust preditions to each spatial grid point and anchor size.\r\n",
        "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(\r\n",
        "        grid_shape[::-1], K.dtype(feats)\r\n",
        "    )\r\n",
        "    box_wh = (\r\n",
        "        K.exp(feats[..., 2:4])\r\n",
        "        * anchors_tensor\r\n",
        "        / K.cast(input_shape[::-1], K.dtype(feats))\r\n",
        "    )\r\n",
        "    box_confidence = K.sigmoid(feats[..., 4:5])\r\n",
        "    box_class_probs = K.sigmoid(feats[..., 5:])\r\n",
        "\r\n",
        "    if calc_loss == True:\r\n",
        "        return grid, feats, box_xy, box_wh\r\n",
        "    return box_xy, box_wh, box_confidence, box_class_probs\r\n",
        "\r\n",
        "def yolo_loss(args, anchors, num_classes, ignore_thresh=0.5, print_loss=False):\r\n",
        "    \r\n",
        "    try:\r\n",
        "        num_layers = len(anchors) // 3  # default setting\r\n",
        "        yolo_outputs = args[:num_layers]\r\n",
        "        y_true = args[num_layers:]\r\n",
        "        anchor_mask = (\r\n",
        "            [[6, 7, 8], [3, 4, 5], [0, 1, 2]] if num_layers == 3 else [[3, 4, 5], [1, 2, 3]]\r\n",
        "        )\r\n",
        "        input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))\r\n",
        "        grid_shapes = [\r\n",
        "            K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0]))\r\n",
        "            for l in range(num_layers)\r\n",
        "        ]\r\n",
        "        loss = 0\r\n",
        "        m = K.shape(yolo_outputs[0])[0]  # batch size, tensor\r\n",
        "        mf = K.cast(m, K.dtype(yolo_outputs[0]))\r\n",
        "\r\n",
        "        for l in range(num_layers):\r\n",
        "            \r\n",
        "            \r\n",
        "            object_mask = y_true[l][..., 4:5]\r\n",
        "            true_class_probs = y_true[l][..., 5:]\r\n",
        "\r\n",
        "            grid, raw_pred, pred_xy, pred_wh = yolo_head(\r\n",
        "                yolo_outputs[l],\r\n",
        "                anchors[anchor_mask[l]],\r\n",
        "                num_classes,\r\n",
        "                input_shape,\r\n",
        "                calc_loss=True,\r\n",
        "            )\r\n",
        "            pred_box = K.concatenate([pred_xy, pred_wh])\r\n",
        "\r\n",
        "            # Darknet raw box to calculate loss.\r\n",
        "            raw_true_xy = y_true[l][..., :2] * grid_shapes[l][::-1] - grid\r\n",
        "            raw_true_wh = K.log(\r\n",
        "                y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1]\r\n",
        "            )\r\n",
        "            raw_true_wh = K.switch(\r\n",
        "                object_mask, raw_true_wh, K.zeros_like(raw_true_wh)\r\n",
        "            )  # avoid log(0)=-inf\r\n",
        "            box_loss_scale = 2 - y_true[l][..., 2:3] * y_true[l][..., 3:4]\r\n",
        "\r\n",
        "            # Find ignore mask, iterate over each of batch.\r\n",
        "            ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\r\n",
        "            object_mask_bool = K.cast(object_mask, \"bool\")\r\n",
        "\r\n",
        "            def loop_body(b, ignore_mask):\r\n",
        "                true_box = tf.boolean_mask(\r\n",
        "                    y_true[l][b, ..., 0:4], object_mask_bool[b, ..., 0])\r\n",
        "                \r\n",
        "                iou = box_iou(pred_box[b], true_box)\r\n",
        "                best_iou = K.max(iou, axis=-1)\r\n",
        "                ignore_mask = ignore_mask.write(\r\n",
        "                    b, K.cast(best_iou < ignore_thresh, K.dtype(true_box)))\r\n",
        "                \r\n",
        "                return b + 1, ignore_mask\r\n",
        "\r\n",
        "            _, ignore_mask = tf.while_loop(lambda b, *args: b < m, loop_body, [0, ignore_mask])\r\n",
        "            \r\n",
        "            ignore_mask = ignore_mask.stack()\r\n",
        "            ignore_mask = K.expand_dims(ignore_mask, -1)\r\n",
        "\r\n",
        "            # K.binary_crossentropy is helpful to avoid exp overflow.\r\n",
        "            \r\n",
        "            xy_loss = (\r\n",
        "            object_mask\r\n",
        "            * box_loss_scale\r\n",
        "            * K.square(raw_true_xy-raw_pred[..., 0:2]))\r\n",
        "            \r\n",
        "            wh_loss = (\r\n",
        "                object_mask\r\n",
        "                * box_loss_scale\r\n",
        "                * 0.5\r\n",
        "                * K.square(raw_true_wh - raw_pred[..., 2:4])\r\n",
        "            )\r\n",
        "\r\n",
        "            confidence_loss = (\r\n",
        "            object_mask\r\n",
        "            * K.binary_crossentropy(object_mask, raw_pred[..., 4:5], from_logits=True)\r\n",
        "            + (1 - object_mask)\r\n",
        "            * K.binary_crossentropy(object_mask, raw_pred[..., 4:5], from_logits=True)\r\n",
        "            * ignore_mask)\r\n",
        "\r\n",
        "            class_loss = object_mask * K.binary_crossentropy(\r\n",
        "                true_class_probs, raw_pred[..., 5:], from_logits=True)\r\n",
        "            \r\n",
        "            \r\n",
        "            xy_loss = K.sum(xy_loss) / mf\r\n",
        "            wh_loss = K.sum(wh_loss) / mf\r\n",
        "            confidence_loss = K.sum(confidence_loss) / mf\r\n",
        "            class_loss = K.sum(class_loss) / mf\r\n",
        "            loss += xy_loss + wh_loss + confidence_loss + class_loss\r\n",
        "    except Exception as error:\r\n",
        "          print(error)\r\n",
        "\r\n",
        "            \r\n",
        "    return loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd5oEvEBMAop"
      },
      "source": [
        "class WeightReader:\r\n",
        "    def __init__(self, weight_file):\r\n",
        "        with open(weight_file, 'rb') as w_f:# r is read and b is binary its whole for read file\r\n",
        "            major,    = struct.unpack('i', w_f.read(4))#struct.unpack base format i is integer and standard size is 4\r\n",
        "            minor,    = struct.unpack('i', w_f.read(4))\r\n",
        "            revision, = struct.unpack('i', w_f.read(4))\r\n",
        "\r\n",
        "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\r\n",
        "                w_f.read(8)\r\n",
        "            else:\r\n",
        "                w_f.read(4)\r\n",
        "\r\n",
        "            transpose = (major > 1000) or (minor > 1000)\r\n",
        "            \r\n",
        "            binary = w_f.read()\r\n",
        "\r\n",
        "        self.offset = 0\r\n",
        "        self.all_weights = np.frombuffer(binary, dtype='float32')\r\n",
        "        \r\n",
        "    def read_bytes(self, size):\r\n",
        "        self.offset = self.offset + size\r\n",
        "        return self.all_weights[self.offset-size:self.offset]\r\n",
        "\r\n",
        "    def load_weights(self, model):\r\n",
        "        for i in range(106):\r\n",
        "            try:\r\n",
        "                conv_layer = model.get_layer('conv_' + str(i))\r\n",
        "                print(\"loading weights of convolution #\" + str(i))\r\n",
        "\r\n",
        "                if i not in [81, 93, 105]:\r\n",
        "                    norm_layer = model.get_layer('bnorm_' + str(i))\r\n",
        "\r\n",
        "                    size = np.prod(norm_layer.get_weights()[0].shape)\r\n",
        "\r\n",
        "                    beta  = self.read_bytes(size) # bias\r\n",
        "                    gamma = self.read_bytes(size) # scale\r\n",
        "                    mean  = self.read_bytes(size) # mean\r\n",
        "                    var   = self.read_bytes(size) # variance            \r\n",
        "\r\n",
        "                    weights = norm_layer.set_weights([gamma, beta, mean, var])  \r\n",
        "\r\n",
        "                if len(conv_layer.get_weights()) > 1:\r\n",
        "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\r\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\r\n",
        "                    \r\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\r\n",
        "                    kernel = kernel.transpose([2,3,1,0])\r\n",
        "                    conv_layer.set_weights([kernel, bias])\r\n",
        "                else:\r\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\r\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\r\n",
        "                    kernel = kernel.transpose([2,3,1,0])\r\n",
        "                    conv_layer.set_weights([kernel])\r\n",
        "            except ValueError:\r\n",
        "                print(\"no convolution #\" + str(i))     \r\n",
        "    \r\n",
        "    def reset(self):\r\n",
        "        self.offset = 0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ybqAF15KpqC"
      },
      "source": [
        "input_shape=(416,416)\r\n",
        "\r\n",
        "\r\n",
        "h, w = input_shape\r\n",
        "\r\n",
        "anchors = np.array([[ 10,13],\r\n",
        "       [16,30],\r\n",
        "       [ 33,  23],\r\n",
        "       [ 30,61],\r\n",
        "       [62,45],\r\n",
        "       [ 59,119],\r\n",
        "       [ 116,90],\r\n",
        "       [156,198],\r\n",
        "       [ 373,326]])\r\n",
        "\r\n",
        "num_anchors = len(anchors)\r\n",
        "\r\n",
        "num_classes=1\r\n",
        "\r\n",
        "\r\n",
        "y_true = [ Input(shape=(h // {0: 32, 1: 16, 2: 8}[l], w // {0: 32, 1: 16, 2: 8}[l], num_anchors // 3,\r\n",
        "         num_classes + 5,\r\n",
        "            ))\r\n",
        "        for l in range(3)]\r\n",
        "\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxwQRLAT9wB6"
      },
      "source": [
        "# Load weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCnvav_bMKVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5f875c-677c-4365-87e0-c3da658522e8"
      },
      "source": [
        "# this yolov3 model is for one class = face\r\n",
        "yolov3 = make_yolov3_model()\r\n",
        "\r\n",
        "# load the weights trained on COCO into the model\r\n",
        "weight_reader = WeightReader('/content/drive/MyDrive/NewYolov3onlyTrain/yolov3.weights')\r\n",
        "weight_reader.load_weights(yolov3)\r\n",
        "\r\n",
        "#yolov3.load_weights(\"/content/drive/MyDrive/NewYolov3onlyTrain/1train17.h5\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading weights of convolution #0\n",
            "loading weights of convolution #1\n",
            "loading weights of convolution #2\n",
            "loading weights of convolution #3\n",
            "no convolution #4\n",
            "loading weights of convolution #5\n",
            "loading weights of convolution #6\n",
            "loading weights of convolution #7\n",
            "no convolution #8\n",
            "loading weights of convolution #9\n",
            "loading weights of convolution #10\n",
            "no convolution #11\n",
            "loading weights of convolution #12\n",
            "loading weights of convolution #13\n",
            "loading weights of convolution #14\n",
            "no convolution #15\n",
            "loading weights of convolution #16\n",
            "loading weights of convolution #17\n",
            "no convolution #18\n",
            "loading weights of convolution #19\n",
            "loading weights of convolution #20\n",
            "no convolution #21\n",
            "loading weights of convolution #22\n",
            "loading weights of convolution #23\n",
            "no convolution #24\n",
            "loading weights of convolution #25\n",
            "loading weights of convolution #26\n",
            "no convolution #27\n",
            "loading weights of convolution #28\n",
            "loading weights of convolution #29\n",
            "no convolution #30\n",
            "loading weights of convolution #31\n",
            "loading weights of convolution #32\n",
            "no convolution #33\n",
            "loading weights of convolution #34\n",
            "loading weights of convolution #35\n",
            "no convolution #36\n",
            "loading weights of convolution #37\n",
            "loading weights of convolution #38\n",
            "loading weights of convolution #39\n",
            "no convolution #40\n",
            "loading weights of convolution #41\n",
            "loading weights of convolution #42\n",
            "no convolution #43\n",
            "loading weights of convolution #44\n",
            "loading weights of convolution #45\n",
            "no convolution #46\n",
            "loading weights of convolution #47\n",
            "loading weights of convolution #48\n",
            "no convolution #49\n",
            "loading weights of convolution #50\n",
            "loading weights of convolution #51\n",
            "no convolution #52\n",
            "loading weights of convolution #53\n",
            "loading weights of convolution #54\n",
            "no convolution #55\n",
            "loading weights of convolution #56\n",
            "loading weights of convolution #57\n",
            "no convolution #58\n",
            "loading weights of convolution #59\n",
            "loading weights of convolution #60\n",
            "no convolution #61\n",
            "loading weights of convolution #62\n",
            "loading weights of convolution #63\n",
            "loading weights of convolution #64\n",
            "no convolution #65\n",
            "loading weights of convolution #66\n",
            "loading weights of convolution #67\n",
            "no convolution #68\n",
            "loading weights of convolution #69\n",
            "loading weights of convolution #70\n",
            "no convolution #71\n",
            "loading weights of convolution #72\n",
            "loading weights of convolution #73\n",
            "no convolution #74\n",
            "loading weights of convolution #75\n",
            "loading weights of convolution #76\n",
            "loading weights of convolution #77\n",
            "loading weights of convolution #78\n",
            "loading weights of convolution #79\n",
            "loading weights of convolution #80\n",
            "loading weights of convolution #81\n",
            "no convolution #82\n",
            "no convolution #83\n",
            "loading weights of convolution #84\n",
            "no convolution #85\n",
            "no convolution #86\n",
            "loading weights of convolution #87\n",
            "loading weights of convolution #88\n",
            "loading weights of convolution #89\n",
            "loading weights of convolution #90\n",
            "loading weights of convolution #91\n",
            "loading weights of convolution #92\n",
            "loading weights of convolution #93\n",
            "no convolution #94\n",
            "no convolution #95\n",
            "loading weights of convolution #96\n",
            "no convolution #97\n",
            "no convolution #98\n",
            "loading weights of convolution #99\n",
            "loading weights of convolution #100\n",
            "loading weights of convolution #101\n",
            "loading weights of convolution #102\n",
            "loading weights of convolution #103\n",
            "loading weights of convolution #104\n",
            "loading weights of convolution #105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRrkyKed93YZ"
      },
      "source": [
        "# Freez 2 end layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFdScRN9QP6w"
      },
      "source": [
        "'''freeze_body=2\r\n",
        "if freeze_body in [1, 2]:\r\n",
        "            # Freeze darknet53 body or freeze all but 3 output layers.\r\n",
        "            num = (185, len(yolov3.layers) - 3)[freeze_body - 1]\r\n",
        "            for i in range(num):\r\n",
        "               yolov3.layers[i].trainable = False\r\n",
        "            print(\"Freeze the first {} layers of total {} layers.\".format(num, len(yolov3.layers)))'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0kNXUd2AAPe"
      },
      "source": [
        "# Add loss layer to model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE1RqP-oML2a"
      },
      "source": [
        "model_loss = Lambda(\r\n",
        "        yolo_loss,\r\n",
        "        output_shape=(1,),\r\n",
        "        name=\"yolo_loss\",\r\n",
        "        arguments={\r\n",
        "            \"anchors\": anchors,\r\n",
        "            \"num_classes\": num_classes,\r\n",
        "            \"ignore_thresh\": 0.5,\r\n",
        "        },\r\n",
        "    )([*yolov3.output, *y_true])\r\n",
        "model = Model([yolov3.input, *y_true], model_loss)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhsS7g1kWozr",
        "outputId": "2dfaa516-bc61-4703-e4e1-a11e3d059915"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_0 (Conv2D)                 (None, None, None, 3 864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_0 (BatchNormalization)    (None, None, None, 3 128         conv_0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_0 (LeakyReLU)             (None, None, None, 3 0           bnorm_0[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, None, None, 3 0           leaky_0[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, None, None, 6 18432       zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_1 (BatchNormalization)    (None, None, None, 6 256         conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_1 (LeakyReLU)             (None, None, None, 6 0           bnorm_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_2 (Conv2D)                 (None, None, None, 3 2048        leaky_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_2 (BatchNormalization)    (None, None, None, 3 128         conv_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_2 (LeakyReLU)             (None, None, None, 3 0           bnorm_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_3 (Conv2D)                 (None, None, None, 6 18432       leaky_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_3 (BatchNormalization)    (None, None, None, 6 256         conv_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_3 (LeakyReLU)             (None, None, None, 6 0           bnorm_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, None, None, 6 0           leaky_1[0][0]                    \n",
            "                                                                 leaky_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, None, None, 6 0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv_5 (Conv2D)                 (None, None, None, 1 73728       zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_5 (BatchNormalization)    (None, None, None, 1 512         conv_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_5 (LeakyReLU)             (None, None, None, 1 0           bnorm_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_6 (Conv2D)                 (None, None, None, 6 8192        leaky_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_6 (BatchNormalization)    (None, None, None, 6 256         conv_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_6 (LeakyReLU)             (None, None, None, 6 0           bnorm_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7 (Conv2D)                 (None, None, None, 1 73728       leaky_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_7 (BatchNormalization)    (None, None, None, 1 512         conv_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_7 (LeakyReLU)             (None, None, None, 1 0           bnorm_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 1 0           leaky_5[0][0]                    \n",
            "                                                                 leaky_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_9 (Conv2D)                 (None, None, None, 6 8192        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_9 (BatchNormalization)    (None, None, None, 6 256         conv_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_9 (LeakyReLU)             (None, None, None, 6 0           bnorm_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_10 (Conv2D)                (None, None, None, 1 73728       leaky_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_10 (BatchNormalization)   (None, None, None, 1 512         conv_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_10 (LeakyReLU)            (None, None, None, 1 0           bnorm_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 1 0           add_1[0][0]                      \n",
            "                                                                 leaky_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, None, None, 1 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv_12 (Conv2D)                (None, None, None, 2 294912      zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_12 (BatchNormalization)   (None, None, None, 2 1024        conv_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_12 (LeakyReLU)            (None, None, None, 2 0           bnorm_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_13 (Conv2D)                (None, None, None, 1 32768       leaky_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_13 (BatchNormalization)   (None, None, None, 1 512         conv_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_13 (LeakyReLU)            (None, None, None, 1 0           bnorm_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_14 (Conv2D)                (None, None, None, 2 294912      leaky_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_14 (BatchNormalization)   (None, None, None, 2 1024        conv_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_14 (LeakyReLU)            (None, None, None, 2 0           bnorm_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 2 0           leaky_12[0][0]                   \n",
            "                                                                 leaky_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_16 (Conv2D)                (None, None, None, 1 32768       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_16 (BatchNormalization)   (None, None, None, 1 512         conv_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_16 (LeakyReLU)            (None, None, None, 1 0           bnorm_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_17 (Conv2D)                (None, None, None, 2 294912      leaky_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_17 (BatchNormalization)   (None, None, None, 2 1024        conv_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_17 (LeakyReLU)            (None, None, None, 2 0           bnorm_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 2 0           add_3[0][0]                      \n",
            "                                                                 leaky_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_19 (Conv2D)                (None, None, None, 1 32768       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_19 (BatchNormalization)   (None, None, None, 1 512         conv_19[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_19 (LeakyReLU)            (None, None, None, 1 0           bnorm_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_20 (Conv2D)                (None, None, None, 2 294912      leaky_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_20 (BatchNormalization)   (None, None, None, 2 1024        conv_20[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_20 (LeakyReLU)            (None, None, None, 2 0           bnorm_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 2 0           add_4[0][0]                      \n",
            "                                                                 leaky_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_22 (Conv2D)                (None, None, None, 1 32768       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_22 (BatchNormalization)   (None, None, None, 1 512         conv_22[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_22 (LeakyReLU)            (None, None, None, 1 0           bnorm_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_23 (Conv2D)                (None, None, None, 2 294912      leaky_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_23 (BatchNormalization)   (None, None, None, 2 1024        conv_23[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_23 (LeakyReLU)            (None, None, None, 2 0           bnorm_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 2 0           add_5[0][0]                      \n",
            "                                                                 leaky_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_25 (Conv2D)                (None, None, None, 1 32768       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_25 (BatchNormalization)   (None, None, None, 1 512         conv_25[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_25 (LeakyReLU)            (None, None, None, 1 0           bnorm_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_26 (Conv2D)                (None, None, None, 2 294912      leaky_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_26 (BatchNormalization)   (None, None, None, 2 1024        conv_26[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_26 (LeakyReLU)            (None, None, None, 2 0           bnorm_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 2 0           add_6[0][0]                      \n",
            "                                                                 leaky_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_28 (Conv2D)                (None, None, None, 1 32768       add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_28 (BatchNormalization)   (None, None, None, 1 512         conv_28[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_28 (LeakyReLU)            (None, None, None, 1 0           bnorm_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_29 (Conv2D)                (None, None, None, 2 294912      leaky_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_29 (BatchNormalization)   (None, None, None, 2 1024        conv_29[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_29 (LeakyReLU)            (None, None, None, 2 0           bnorm_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 2 0           add_7[0][0]                      \n",
            "                                                                 leaky_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_31 (Conv2D)                (None, None, None, 1 32768       add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_31 (BatchNormalization)   (None, None, None, 1 512         conv_31[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_31 (LeakyReLU)            (None, None, None, 1 0           bnorm_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_32 (Conv2D)                (None, None, None, 2 294912      leaky_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_32 (BatchNormalization)   (None, None, None, 2 1024        conv_32[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_32 (LeakyReLU)            (None, None, None, 2 0           bnorm_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 2 0           add_8[0][0]                      \n",
            "                                                                 leaky_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_34 (Conv2D)                (None, None, None, 1 32768       add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_34 (BatchNormalization)   (None, None, None, 1 512         conv_34[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_34 (LeakyReLU)            (None, None, None, 1 0           bnorm_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_35 (Conv2D)                (None, None, None, 2 294912      leaky_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_35 (BatchNormalization)   (None, None, None, 2 1024        conv_35[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_35 (LeakyReLU)            (None, None, None, 2 0           bnorm_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 2 0           add_9[0][0]                      \n",
            "                                                                 leaky_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, None, None, 2 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_37 (Conv2D)                (None, None, None, 5 1179648     zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_37 (BatchNormalization)   (None, None, None, 5 2048        conv_37[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_37 (LeakyReLU)            (None, None, None, 5 0           bnorm_37[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_38 (Conv2D)                (None, None, None, 2 131072      leaky_37[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_38 (BatchNormalization)   (None, None, None, 2 1024        conv_38[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_38 (LeakyReLU)            (None, None, None, 2 0           bnorm_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_39 (Conv2D)                (None, None, None, 5 1179648     leaky_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_39 (BatchNormalization)   (None, None, None, 5 2048        conv_39[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_39 (LeakyReLU)            (None, None, None, 5 0           bnorm_39[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 5 0           leaky_37[0][0]                   \n",
            "                                                                 leaky_39[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_41 (Conv2D)                (None, None, None, 2 131072      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_41 (BatchNormalization)   (None, None, None, 2 1024        conv_41[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_41 (LeakyReLU)            (None, None, None, 2 0           bnorm_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_42 (Conv2D)                (None, None, None, 5 1179648     leaky_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_42 (BatchNormalization)   (None, None, None, 5 2048        conv_42[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_42 (LeakyReLU)            (None, None, None, 5 0           bnorm_42[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 5 0           add_11[0][0]                     \n",
            "                                                                 leaky_42[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_44 (Conv2D)                (None, None, None, 2 131072      add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_44 (BatchNormalization)   (None, None, None, 2 1024        conv_44[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_44 (LeakyReLU)            (None, None, None, 2 0           bnorm_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_45 (Conv2D)                (None, None, None, 5 1179648     leaky_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_45 (BatchNormalization)   (None, None, None, 5 2048        conv_45[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_45 (LeakyReLU)            (None, None, None, 5 0           bnorm_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 5 0           add_12[0][0]                     \n",
            "                                                                 leaky_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_47 (Conv2D)                (None, None, None, 2 131072      add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_47 (BatchNormalization)   (None, None, None, 2 1024        conv_47[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_47 (LeakyReLU)            (None, None, None, 2 0           bnorm_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_48 (Conv2D)                (None, None, None, 5 1179648     leaky_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_48 (BatchNormalization)   (None, None, None, 5 2048        conv_48[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_48 (LeakyReLU)            (None, None, None, 5 0           bnorm_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 5 0           add_13[0][0]                     \n",
            "                                                                 leaky_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_50 (Conv2D)                (None, None, None, 2 131072      add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_50 (BatchNormalization)   (None, None, None, 2 1024        conv_50[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_50 (LeakyReLU)            (None, None, None, 2 0           bnorm_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_51 (Conv2D)                (None, None, None, 5 1179648     leaky_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_51 (BatchNormalization)   (None, None, None, 5 2048        conv_51[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_51 (LeakyReLU)            (None, None, None, 5 0           bnorm_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 5 0           add_14[0][0]                     \n",
            "                                                                 leaky_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_53 (Conv2D)                (None, None, None, 2 131072      add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_53 (BatchNormalization)   (None, None, None, 2 1024        conv_53[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_53 (LeakyReLU)            (None, None, None, 2 0           bnorm_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_54 (Conv2D)                (None, None, None, 5 1179648     leaky_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_54 (BatchNormalization)   (None, None, None, 5 2048        conv_54[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_54 (LeakyReLU)            (None, None, None, 5 0           bnorm_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 5 0           add_15[0][0]                     \n",
            "                                                                 leaky_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_56 (Conv2D)                (None, None, None, 2 131072      add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_56 (BatchNormalization)   (None, None, None, 2 1024        conv_56[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_56 (LeakyReLU)            (None, None, None, 2 0           bnorm_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_57 (Conv2D)                (None, None, None, 5 1179648     leaky_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_57 (BatchNormalization)   (None, None, None, 5 2048        conv_57[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_57 (LeakyReLU)            (None, None, None, 5 0           bnorm_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, None, None, 5 0           add_16[0][0]                     \n",
            "                                                                 leaky_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_59 (Conv2D)                (None, None, None, 2 131072      add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_59 (BatchNormalization)   (None, None, None, 2 1024        conv_59[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_59 (LeakyReLU)            (None, None, None, 2 0           bnorm_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_60 (Conv2D)                (None, None, None, 5 1179648     leaky_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_60 (BatchNormalization)   (None, None, None, 5 2048        conv_60[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_60 (LeakyReLU)            (None, None, None, 5 0           bnorm_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, None, None, 5 0           add_17[0][0]                     \n",
            "                                                                 leaky_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, None, None, 5 0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_62 (Conv2D)                (None, None, None, 1 4718592     zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_62 (BatchNormalization)   (None, None, None, 1 4096        conv_62[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_62 (LeakyReLU)            (None, None, None, 1 0           bnorm_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_63 (Conv2D)                (None, None, None, 5 524288      leaky_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_63 (BatchNormalization)   (None, None, None, 5 2048        conv_63[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_63 (LeakyReLU)            (None, None, None, 5 0           bnorm_63[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_64 (Conv2D)                (None, None, None, 1 4718592     leaky_63[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_64 (BatchNormalization)   (None, None, None, 1 4096        conv_64[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_64 (LeakyReLU)            (None, None, None, 1 0           bnorm_64[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, None, None, 1 0           leaky_62[0][0]                   \n",
            "                                                                 leaky_64[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_66 (Conv2D)                (None, None, None, 5 524288      add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_66 (BatchNormalization)   (None, None, None, 5 2048        conv_66[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_66 (LeakyReLU)            (None, None, None, 5 0           bnorm_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_67 (Conv2D)                (None, None, None, 1 4718592     leaky_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_67 (BatchNormalization)   (None, None, None, 1 4096        conv_67[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_67 (LeakyReLU)            (None, None, None, 1 0           bnorm_67[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, None, None, 1 0           add_19[0][0]                     \n",
            "                                                                 leaky_67[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_69 (Conv2D)                (None, None, None, 5 524288      add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_69 (BatchNormalization)   (None, None, None, 5 2048        conv_69[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_69 (LeakyReLU)            (None, None, None, 5 0           bnorm_69[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_70 (Conv2D)                (None, None, None, 1 4718592     leaky_69[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_70 (BatchNormalization)   (None, None, None, 1 4096        conv_70[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_70 (LeakyReLU)            (None, None, None, 1 0           bnorm_70[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, None, None, 1 0           add_20[0][0]                     \n",
            "                                                                 leaky_70[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_72 (Conv2D)                (None, None, None, 5 524288      add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_72 (BatchNormalization)   (None, None, None, 5 2048        conv_72[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_72 (LeakyReLU)            (None, None, None, 5 0           bnorm_72[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_73 (Conv2D)                (None, None, None, 1 4718592     leaky_72[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_73 (BatchNormalization)   (None, None, None, 1 4096        conv_73[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_73 (LeakyReLU)            (None, None, None, 1 0           bnorm_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, None, None, 1 0           add_21[0][0]                     \n",
            "                                                                 leaky_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_75 (Conv2D)                (None, None, None, 5 524288      add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_75 (BatchNormalization)   (None, None, None, 5 2048        conv_75[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_75 (LeakyReLU)            (None, None, None, 5 0           bnorm_75[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_76 (Conv2D)                (None, None, None, 1 4718592     leaky_75[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_76 (BatchNormalization)   (None, None, None, 1 4096        conv_76[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_76 (LeakyReLU)            (None, None, None, 1 0           bnorm_76[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_77 (Conv2D)                (None, None, None, 5 524288      leaky_76[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_77 (BatchNormalization)   (None, None, None, 5 2048        conv_77[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_77 (LeakyReLU)            (None, None, None, 5 0           bnorm_77[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_78 (Conv2D)                (None, None, None, 1 4718592     leaky_77[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_78 (BatchNormalization)   (None, None, None, 1 4096        conv_78[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_78 (LeakyReLU)            (None, None, None, 1 0           bnorm_78[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_79 (Conv2D)                (None, None, None, 5 524288      leaky_78[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_79 (BatchNormalization)   (None, None, None, 5 2048        conv_79[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_79 (LeakyReLU)            (None, None, None, 5 0           bnorm_79[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_84 (Conv2D)                (None, None, None, 2 131072      leaky_79[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_84 (BatchNormalization)   (None, None, None, 2 1024        conv_84[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_84 (LeakyReLU)            (None, None, None, 2 0           bnorm_84[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, None, None, 2 0           leaky_84[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, None, None, 7 0           up_sampling2d[0][0]              \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_87 (Conv2D)                (None, None, None, 2 196608      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_87 (BatchNormalization)   (None, None, None, 2 1024        conv_87[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_87 (LeakyReLU)            (None, None, None, 2 0           bnorm_87[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_88 (Conv2D)                (None, None, None, 5 1179648     leaky_87[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_88 (BatchNormalization)   (None, None, None, 5 2048        conv_88[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_88 (LeakyReLU)            (None, None, None, 5 0           bnorm_88[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_89 (Conv2D)                (None, None, None, 2 131072      leaky_88[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_89 (BatchNormalization)   (None, None, None, 2 1024        conv_89[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_89 (LeakyReLU)            (None, None, None, 2 0           bnorm_89[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_90 (Conv2D)                (None, None, None, 5 1179648     leaky_89[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_90 (BatchNormalization)   (None, None, None, 5 2048        conv_90[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_90 (LeakyReLU)            (None, None, None, 5 0           bnorm_90[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_91 (Conv2D)                (None, None, None, 2 131072      leaky_90[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_91 (BatchNormalization)   (None, None, None, 2 1024        conv_91[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_91 (LeakyReLU)            (None, None, None, 2 0           bnorm_91[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_96 (Conv2D)                (None, None, None, 1 32768       leaky_91[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_96 (BatchNormalization)   (None, None, None, 1 512         conv_96[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_96 (LeakyReLU)            (None, None, None, 1 0           bnorm_96[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, None, None, 1 0           leaky_96[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 3 0           up_sampling2d_1[0][0]            \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_99 (Conv2D)                (None, None, None, 1 49152       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_99 (BatchNormalization)   (None, None, None, 1 512         conv_99[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_99 (LeakyReLU)            (None, None, None, 1 0           bnorm_99[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_100 (Conv2D)               (None, None, None, 2 294912      leaky_99[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_100 (BatchNormalization)  (None, None, None, 2 1024        conv_100[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_100 (LeakyReLU)           (None, None, None, 2 0           bnorm_100[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_101 (Conv2D)               (None, None, None, 1 32768       leaky_100[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_101 (BatchNormalization)  (None, None, None, 1 512         conv_101[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_101 (LeakyReLU)           (None, None, None, 1 0           bnorm_101[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_102 (Conv2D)               (None, None, None, 2 294912      leaky_101[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_102 (BatchNormalization)  (None, None, None, 2 1024        conv_102[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_102 (LeakyReLU)           (None, None, None, 2 0           bnorm_102[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_103 (Conv2D)               (None, None, None, 1 32768       leaky_102[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_103 (BatchNormalization)  (None, None, None, 1 512         conv_103[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_103 (LeakyReLU)           (None, None, None, 1 0           bnorm_103[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_80 (Conv2D)                (None, None, None, 1 4718592     leaky_79[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_92 (Conv2D)                (None, None, None, 5 1179648     leaky_91[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_104 (Conv2D)               (None, None, None, 2 294912      leaky_103[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_80 (BatchNormalization)   (None, None, None, 1 4096        conv_80[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_92 (BatchNormalization)   (None, None, None, 5 2048        conv_92[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_104 (BatchNormalization)  (None, None, None, 2 1024        conv_104[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_80 (LeakyReLU)            (None, None, None, 1 0           bnorm_80[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_92 (LeakyReLU)            (None, None, None, 5 0           bnorm_92[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_104 (LeakyReLU)           (None, None, None, 2 0           bnorm_104[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_81 (Conv2D)                (None, None, None, 1 18450       leaky_80[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_93 (Conv2D)                (None, None, None, 1 9234        leaky_92[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_105 (Conv2D)               (None, None, None, 1 4626        leaky_104[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 13, 13, 3, 6 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 26, 26, 3, 6 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 52, 52, 3, 6 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "yolo_loss (Lambda)              ()                   0           conv_81[0][0]                    \n",
            "                                                                 conv_93[0][0]                    \n",
            "                                                                 conv_105[0][0]                   \n",
            "                                                                 input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 61,576,342\n",
            "Trainable params: 61,523,734\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp7wO6bxOyQB"
      },
      "source": [
        "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\r\n",
        "    \"\"\"Preprocess true boxes to training input format\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    true_boxes: array, shape=(m, T, 5)\r\n",
        "        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.\r\n",
        "    input_shape: array-like, hw, multiples of 32\r\n",
        "    anchors: array, shape=(N, 2), wh\r\n",
        "    num_classes: integer\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    y_true: list of array, shape like yolo_outputs, xywh are reletive value\r\n",
        "    \"\"\"\r\n",
        "    assert (\r\n",
        "        true_boxes[..., 4] <= num_classes\r\n",
        "    ).all(), \"class id must be less than num_classes\"\r\n",
        "    num_layers = len(anchors) // 3  # default setting\r\n",
        "    anchor_mask = (\r\n",
        "        [[6, 7, 8], [3, 4, 5], [0, 1, 2]] if num_layers == 3 else [[3, 4, 5], [1, 2, 3]]\r\n",
        "    )\r\n",
        "\r\n",
        "    \r\n",
        "    \r\n",
        "    true_boxes = np.array(true_boxes, dtype=\"float32\")\r\n",
        "    input_shape = np.array(input_shape, dtype=\"int32\")\r\n",
        "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\r\n",
        "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\r\n",
        "    true_boxes[..., 0:2] = boxes_xy / input_shape[::-1]\r\n",
        "    true_boxes[..., 2:4] = boxes_wh / input_shape[::-1]\r\n",
        "\r\n",
        "    m = true_boxes.shape[0]\r\n",
        "    grid_shapes = [input_shape // {0: 32, 1: 16, 2: 8}[l] for l in range(num_layers)]\r\n",
        "    y_true = [\r\n",
        "        np.zeros(\r\n",
        "            (\r\n",
        "                m,\r\n",
        "                grid_shapes[l][0],\r\n",
        "                grid_shapes[l][1],\r\n",
        "                len(anchor_mask[l]),\r\n",
        "                5 + num_classes,\r\n",
        "            ),\r\n",
        "            dtype=\"float32\",\r\n",
        "        )\r\n",
        "        for l in range(num_layers)\r\n",
        "    ]\r\n",
        "\r\n",
        "    # Expand dim to apply broadcasting.\r\n",
        "    anchors = np.expand_dims(anchors, 0)\r\n",
        "    anchor_maxes = anchors / 2.0\r\n",
        "    anchor_mins = -anchor_maxes\r\n",
        "    valid_mask = boxes_wh[..., 0] > 0\r\n",
        "\r\n",
        "    for b in range(m):\r\n",
        "        # Discard zero rows.\r\n",
        "        wh = boxes_wh[b, valid_mask[b]]\r\n",
        "        if len(wh) == 0:\r\n",
        "            continue\r\n",
        "        # Expand dim to apply broadcasting.\r\n",
        "        wh = np.expand_dims(wh, -2)\r\n",
        "        box_maxes = wh / 2.0\r\n",
        "        box_mins = -box_maxes\r\n",
        "\r\n",
        "        intersect_mins = np.maximum(box_mins, anchor_mins)\r\n",
        "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\r\n",
        "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.0)\r\n",
        "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\r\n",
        "        box_area = wh[..., 0] * wh[..., 1]\r\n",
        "        anchor_area = anchors[..., 0] * anchors[..., 1]\r\n",
        "        iou = intersect_area / (box_area + anchor_area - intersect_area)\r\n",
        "\r\n",
        "        # Find best anchor for each true box\r\n",
        "        best_anchor = np.argmax(iou, axis=-1)\r\n",
        "\r\n",
        "        for t, n in enumerate(best_anchor):\r\n",
        "            for l in range(num_layers):\r\n",
        "                if n in anchor_mask[l]:\r\n",
        "                    i = np.floor(true_boxes[b, t, 0] * grid_shapes[l][1]).astype(\r\n",
        "                        \"int32\"\r\n",
        "                    )\r\n",
        "                    j = np.floor(true_boxes[b, t, 1] * grid_shapes[l][0]).astype(\r\n",
        "                        \"int32\"\r\n",
        "                    )\r\n",
        "                    k = anchor_mask[l].index(n)\r\n",
        "                    c = true_boxes[b, t, 4].astype(\"int32\")\r\n",
        "                    \r\n",
        "                    if y_true[l][b, j, i, k, 4]!=1:\r\n",
        "                        y_true[l][b, j, i, k, 0:4] = true_boxes[b, t, 0:4]\r\n",
        "                        y_true[l][b, j, i, k, 4] = 1\r\n",
        "                        y_true[l][b, j, i, k, 5] =1\r\n",
        "                \r\n",
        "\r\n",
        "    return y_true\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj0i4o50Nn-k"
      },
      "source": [
        "\r\n",
        "def get_data_train(address):\r\n",
        "        dict_box_name={}\r\n",
        "        file_line=[]\r\n",
        "        zero=0\r\n",
        "        file = open(address, \"r\")\r\n",
        "        for line in file:\r\n",
        "            file_line.append(line)\r\n",
        " \r\n",
        "        #len(dict_box_name.keys()) 12880\r\n",
        "        invalid=0\r\n",
        "        i=0\r\n",
        "        array = []\r\n",
        "        class_object = {}\r\n",
        "        while i < len(file_line):\r\n",
        "            name = file_line[i].split('\\n')[0]\r\n",
        "            i = i + 1\r\n",
        "            number = int(file_line[i].split('\\n')[0])\r\n",
        "\r\n",
        "            if number ==0:\r\n",
        "              number=1   # because it get one row \r\n",
        "            i=i+1\r\n",
        "            end = i+number\r\n",
        "            start = i\r\n",
        "            array = []\r\n",
        "            while start < end:\r\n",
        "\r\n",
        "                temp = np.array(file_line[start].split(' ')[0:8])\r\n",
        "                temp = temp.astype('int32') \r\n",
        "                \r\n",
        "                if temp[2]!=0 and temp[3]!=0:\r\n",
        "                    \r\n",
        "                    if temp[7]==0:\r\n",
        "                        temp = np.array(file_line[start].split(' ')[0:5])\r\n",
        "                        temp = temp.astype('int32') \r\n",
        "                        temp[2]=temp[0]+temp[2]\r\n",
        "                        temp[3]=temp[1]+temp[3]\r\n",
        "  \r\n",
        "                        temp[4]=0\r\n",
        "                          \r\n",
        "                        array.append(temp[0:5])\r\n",
        "                    elif temp[7]==1:\r\n",
        "                      invalid=invalid+1\r\n",
        "                else:\r\n",
        "                  zero=zero+1\r\n",
        "\r\n",
        "\r\n",
        "                start = start+1\r\n",
        "            if len(array)!=0:\r\n",
        "                 dict_box_name[name] =array\r\n",
        " \r\n",
        "            i=end\r\n",
        "        print(\"number of invalid data =\",invalid,\"number of zero =\",zero)#2399 31\r\n",
        "        return dict_box_name"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNuczPXuAQhr"
      },
      "source": [
        "# Name and coordinate data read from txt train file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FqHJV1TKqKj",
        "outputId": "4a3e1264-79fc-481a-ebf0-0bb98eda3ba5"
      },
      "source": [
        "\r\n",
        "address_file='/content/drive/My Drive/widerface/'\r\n",
        "\r\n",
        "address_train_txt = address_file+\"/wider_face_train_bbx_gt (2).txt\"#box 159393 in train---------->156994\r\n",
        "address_train =address_file+'/WIDER_train/images/'\r\n",
        "\r\n",
        "anchors = np.array([[ 10,13],\r\n",
        "       [16,30],\r\n",
        "       [ 33,  23],\r\n",
        "       [ 30,61],\r\n",
        "       [62,45],\r\n",
        "       [ 59,119],\r\n",
        "       [ 116,90],\r\n",
        "       [156,198],\r\n",
        "       [ 373,326]])\r\n",
        "\r\n",
        "input_shape = (416, 416)  # multiple of 32, hw\r\n",
        "\r\n",
        "data_train = get_data_train(address_train_txt )#12880------------>12876\r\n",
        "\r\n",
        "num_train = len(data_train.keys())\r\n",
        "\r\n",
        "dict_key_train=list(data_train.keys())\r\n",
        "\r\n",
        "num_classes=1\r\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of invalid data = 2399 number of zero = 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3LGKbabFFX4"
      },
      "source": [
        "# Split data train and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YD5_ufZNw2A"
      },
      "source": [
        "\r\n",
        "X = []\r\n",
        "Y = []\r\n",
        "\r\n",
        "for item in dict_key_train:\r\n",
        "  X.append(item)\r\n",
        "  arr = []\r\n",
        "  Y.append(data_train[item])\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gktD_380NzBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e114d6-8180-4c74-967a-c18177b777e2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.15,shuffle=True)\r\n",
        "\r\n",
        "num_val=len(Y_val)\r\n",
        "num_train=len(Y_train)\r\n",
        "\r\n",
        "num_val,num_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1932, 10944)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iodg8PoMLSK_"
      },
      "source": [
        "data_train_split={}\r\n",
        "data_valid_split={}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDwdnkx-N3YZ"
      },
      "source": [
        "for i in range(len(X_train)):\r\n",
        "  data_train_split[X_train[i]]=Y_train[i]\r\n",
        "for j in range(len(X_val)):\r\n",
        "  data_valid_split[X_val[j]]=Y_val[j]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvjq-2D3N51S"
      },
      "source": [
        "def data_generator_wrapper(address , data_array, batch_size, input_shape, anchors, num_classes):\r\n",
        "    n = len(data_array)\r\n",
        "    if n == 0 or batch_size <= 0:\r\n",
        "        return None\r\n",
        "    \r\n",
        "    return  data_generator(address ,data_array, batch_size, input_shape, anchors, num_classes)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-80o5syN7IR"
      },
      "source": [
        "    \r\n",
        "def data_generator(address , annotation_lines, batch_size, input_shape, anchors, num_classes):\r\n",
        "      array_key = []\r\n",
        "      for key in annotation_lines.keys(): \r\n",
        "          array_key.append(key)\r\n",
        "      n = len(annotation_lines)\r\n",
        "      i = 0\r\n",
        "      while True:\r\n",
        "          image_data = []\r\n",
        "          box_data = []\r\n",
        "          for b in range(batch_size):\r\n",
        "              if i == 0:\r\n",
        "                  np.random.shuffle(array_key)\r\n",
        "          \r\n",
        "              image, box = get_random_data(address, array_key[i], annotation_lines, input_shape, random=True)\r\n",
        "\r\n",
        "              image_data.append(image)\r\n",
        "              box_data.append(box)\r\n",
        "              i = (i + 1) % n\r\n",
        "          image_data = np.array(image_data)\r\n",
        "          box_data = np.array(box_data)\r\n",
        "          \r\n",
        "          y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\r\n",
        "        \r\n",
        "          yield [image_data, *y_true], np.zeros(batch_size)# all = b len(b[0]) = 4 and len(b[1]) = 1 shape=(1,)\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_mOMMMn0ANR"
      },
      "source": [
        "\r\n",
        "def rand(a=0, b=1):\r\n",
        "    return np.random.rand() * (b - a) + a\r\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVZwYPFlEW3q"
      },
      "source": [
        "\r\n",
        "\r\n",
        "model_checkpoint = callbacks.ModelCheckpoint('/content/drive/MyDrive/NewYolov3onlyTrain/xxx{epoch}.h5')\r\n",
        "log_checkpoint = callbacks.CSVLogger('/content/drive/MyDrive/NewYolov3onlyTrain/xxx.log')\r\n",
        "callback_model = [log_checkpoint, model_checkpoint]\r\n",
        "batch_size = 16\r\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrJ1NYYSb-I2"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "tEXV1CJ-0Fjw",
        "outputId": "f6cb7fda-1dad-49d8-f00e-056d915d788a"
      },
      "source": [
        "\r\n",
        "model.compile( optimizer=Adam(lr=1e-4),loss={\"yolo_loss\": lambda y_true, y_pred: y_pred},)\r\n",
        "# use custom yolo_loss Lambda layer.\r\n",
        "\r\n",
        "print(  \"Train on {} samples, val on {} samples, with batch size {}.\".format( num_train, num_val, batch_size)  )\r\n",
        "print(num_classes)\r\n",
        "\r\n",
        "model.fit_generator(\r\n",
        "    data_generator_wrapper(address_train,data_train_split, batch_size, input_shape, anchors, num_classes ),\r\n",
        "\r\n",
        "    steps_per_epoch = max(1, num_train  // batch_size),\r\n",
        "\r\n",
        "    validation_data = data_generator_wrapper(address_train, data_valid_split, batch_size, input_shape, anchors, num_classes ),\r\n",
        "\r\n",
        "    validation_steps = max(1, num_val  // batch_size),\r\n",
        "\r\n",
        "    epochs = 20,\r\n",
        "    \r\n",
        "    initial_epoch = 0,\r\n",
        "    callbacks = callback_model\r\n",
        ")\r\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10944 samples, val on 1932 samples, with batch size 16.\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "  4/684 [..............................] - ETA: 2:01:14 - loss: 7023.4500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b359cb2c59bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}